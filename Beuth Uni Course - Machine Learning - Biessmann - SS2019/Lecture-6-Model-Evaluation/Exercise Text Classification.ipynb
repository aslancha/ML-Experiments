{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification\n",
    "\n",
    "In dieser Aufgabe werden Sie eine Text Classification Pipeline bauen, die Partei gegeben einen Text vorhersagt. \n",
    "Statt der Parlamentsdebatten koennen Sie auch gerne einen anderen Text Datensatz nehmen, wenn Sie einen guten finden.\n",
    "Stellen Sie aber sicher, dass Ihre Kollegen Zugriff auf die Daten haben fuer die Korrektur. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, gzip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "DATADIR = \"data\"\n",
    "\n",
    "if not os.path.exists(DATADIR): \n",
    "    os.mkdir(DATADIR)\n",
    "\n",
    "file_name = os.path.join(DATADIR, 'bundestags_parlamentsprotokolle.csv.gzip')\n",
    "if not os.path.exists(file_name):\n",
    "    url_data = 'https://www.dropbox.com/s/1nlbfehnrwwa2zj/bundestags_parlamentsprotokolle.csv.gzip?dl=1'\n",
    "    urllib.request.urlretrieve(url_data, file_name)\n",
    "\n",
    "df = pd.read_csv(gzip.open(file_name), index_col=0).sample(frac=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ein Auszug der Parlamentsdebatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sitzung</th>\n",
       "      <th>wahlperiode</th>\n",
       "      <th>sprecher</th>\n",
       "      <th>text</th>\n",
       "      <th>partei</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42752</th>\n",
       "      <td>234</td>\n",
       "      <td>18</td>\n",
       "      <td>Dr. André Hahn</td>\n",
       "      <td>Frau Präsidentin! Meine Damen und Herren! Durc...</td>\n",
       "      <td>linke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13898</th>\n",
       "      <td>159</td>\n",
       "      <td>17</td>\n",
       "      <td>Jimmy Schulz</td>\n",
       "      <td>Natürlich gibt es Probleme bei der Ausbildung ...</td>\n",
       "      <td>fdp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24828</th>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>Dennis Rohde</td>\n",
       "      <td>Wir alle wissen doch: Meistens trifft es die S...</td>\n",
       "      <td>spd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10093</th>\n",
       "      <td>120</td>\n",
       "      <td>17</td>\n",
       "      <td>Kerstin Griese</td>\n",
       "      <td>Insofern ist meine Entscheidung auch frauenpol...</td>\n",
       "      <td>spd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sitzung  wahlperiode        sprecher  \\\n",
       "42752      234           18  Dr. André Hahn   \n",
       "13898      159           17    Jimmy Schulz   \n",
       "24828       17           18    Dennis Rohde   \n",
       "10093      120           17  Kerstin Griese   \n",
       "\n",
       "                                                    text partei  \n",
       "42752  Frau Präsidentin! Meine Damen und Herren! Durc...  linke  \n",
       "13898  Natürlich gibt es Probleme bei der Ausbildung ...    fdp  \n",
       "24828  Wir alle wissen doch: Meistens trifft es die S...    spd  \n",
       "10093  Insofern ist meine Entscheidung auch frauenpol...    spd  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitten Sie die Daten in Train (80%) und Test (20%), dafuer koennen sie die sklearn train_test_split function benutzen. \n",
    "\n",
    "Dann trainieren Sie eine Pipeline mit einem geeigneten Vectorizer und einem sklearn Modell Ihrer Wahl. \n",
    "\n",
    "Vergleichen Sie die Precision/Recall/F1 und Accuracy auf dem Train und Test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data and labels into train and test data, train and test labels\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(df['text'], df['partei'], test_size=0.2)\n",
    "vect    = TfidfVectorizer(max_features = int(1e8))                      # construct feature extraction object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      cducsu       0.48      0.63      0.54      2479\n",
      "         fdp       0.38      0.19      0.25      1402\n",
      "      gruene       0.39      0.32      0.35      1541\n",
      "       linke       0.56      0.36      0.44      1829\n",
      "         spd       0.27      0.44      0.34      1485\n",
      "\n",
      "    accuracy                           0.41      8736\n",
      "   macro avg       0.42      0.39      0.38      8736\n",
      "weighted avg       0.43      0.41      0.41      8736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ncc     = NearestCentroid()                                             # construct Nearest Centroid Classifier Object\n",
    "ncc_clf = Pipeline([('vect', vect),('clf', ncc)])                       # construct Pipeline Object with Feature Extractor and Classifier\n",
    "ncc_clf.fit(train_data, train_labels)                                   # train pipeline with training data and labels\n",
    "\n",
    "ncc_predictions = ncc_clf.predict(test_data)                            # predict labels for test data\n",
    "ncc_clf_report  = classification_report(ncc_predictions, test_labels)   # create report by comparing predictions with the labels\n",
    "print(ncc_clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      cducsu       0.90      0.56      0.69      5197\n",
      "         fdp       0.06      0.65      0.10        60\n",
      "      gruene       0.30      0.63      0.41       614\n",
      "       linke       0.66      0.59      0.62      1291\n",
      "         spd       0.39      0.59      0.47      1574\n",
      "\n",
      "    accuracy                           0.58      8736\n",
      "   macro avg       0.46      0.60      0.46      8736\n",
      "weighted avg       0.73      0.58      0.62      8736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sgd        = SGDClassifier()\n",
    "logreg_clf = Pipeline([('vect', vect),('clf', sgd)])\n",
    "logreg_clf.fit(train_data, train_labels)\n",
    "\n",
    "logreg_predictions = logreg_clf.predict(test_data)\n",
    "logreg_clf_report  = classification_report(logreg_predictions, test_labels)\n",
    "print(logreg_clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      cducsu       0.79      0.44      0.57      5792\n",
      "         fdp       0.16      0.21      0.18       521\n",
      "      gruene       0.14      0.40      0.21       444\n",
      "       linke       0.15      0.56      0.24       335\n",
      "         spd       0.32      0.45      0.37      1644\n",
      "\n",
      "    accuracy                           0.43      8736\n",
      "   macro avg       0.31      0.41      0.32      8736\n",
      "weighted avg       0.61      0.43      0.48      8736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knc     = KNeighborsClassifier(3)\n",
    "knc_clf = Pipeline([('vect', vect), ('clf', knc)])\n",
    "knc_clf.fit(train_data, train_labels)\n",
    "\n",
    "knc_predictions = knc_clf.predict(test_data)\n",
    "knc_clf_report  = classification_report(knc_predictions, test_labels)\n",
    "print(knc_clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      cducsu       0.83      0.46      0.59      5858\n",
      "         fdp       0.05      0.40      0.09        83\n",
      "      gruene       0.11      0.42      0.17       325\n",
      "       linke       0.20      0.66      0.30       369\n",
      "         spd       0.31      0.34      0.33      2101\n",
      "\n",
      "    accuracy                           0.44      8736\n",
      "   macro avg       0.30      0.46      0.30      8736\n",
      "weighted avg       0.64      0.44      0.49      8736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc     = DecisionTreeClassifier(max_depth=5)\n",
    "dtc_clf = Pipeline([('vect', vect), ('clf', dtc)])\n",
    "dtc_clf.fit(train_data, train_labels)\n",
    "\n",
    "dtc_predictions = dtc_clf.predict(test_data)\n",
    "dtc_clf_report  = classification_report(dtc_predictions, test_labels)\n",
    "print(dtc_clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      cducsu       0.77      0.52      0.62      4808\n",
      "         fdp       0.13      0.60      0.22       146\n",
      "      gruene       0.25      0.38      0.30       819\n",
      "       linke       0.46      0.45      0.45      1278\n",
      "         spd       0.30      0.42      0.35      1685\n",
      "\n",
      "    accuracy                           0.48      8736\n",
      "   macro avg       0.38      0.47      0.39      8736\n",
      "weighted avg       0.58      0.48      0.51      8736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "adc     = AdaBoostClassifier()\n",
    "adc_clf = Pipeline([('vect', vect), ('clf', adc)])\n",
    "adc_clf.fit(train_data, train_labels)\n",
    "\n",
    "adc_predictions = adc_clf.predict(test_data)\n",
    "adc_clf_report  = classification_report(adc_predictions, test_labels)\n",
    "print(adc_clf_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
