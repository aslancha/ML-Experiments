{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Machine Learning \n",
    "\n",
    "Lecture 4\n",
    "\n",
    "Feature Extraction Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Machine Learning Pipelines\n",
    "\n",
    "![ml-pipeline-2.png](figures/ml-pipeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Feature Extraction\n",
    "\n",
    "- Feature extraction describes the transformations from **data** to **vectors**\n",
    "\n",
    "   \n",
    "- Extracting good features is **more important** than choosing a ML model\n",
    "\n",
    "\n",
    "- We will cover some standard feature extractors, but there are many more\n",
    "\n",
    "\n",
    "- Often the best feature extractors include domain knowledge by human experts\n",
    "\n",
    "\n",
    "- Feature extractors have to be optimized along with all other model parameters\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Feature Extraction\n",
    "   \n",
    "- Continuous Features\n",
    "- Categorical Features\n",
    "- Text (next lecture)\n",
    "- Images (next lecture)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Continuous Features\n",
    "\n",
    "- Continuous features: $x \\in R^{d}$\n",
    "\n",
    "\n",
    "- For many models continuous features don't need to be transformed\n",
    "\n",
    "\n",
    "- For some models it is necessary or beneficial to **normalize** continuous features\n",
    "\n",
    "    - When optimizing with stochastic gradient descent\n",
    "    - When regularizing models: to control regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Normalization: z-scoring\n",
    "\n",
    "Given a feature $x\\in R^1$ (and for multivariate $x$ analogously) there are several standard normalization options:\n",
    "\n",
    "**Standard scaling / z-scoring**: compute mean $\\mu_x$ and standard deviation $\\sigma_x$ of $x$ and compute\n",
    "\n",
    "$$ x \\leftarrow \\frac{(x - \\mu_x) } {\\sigma_x} $$\n",
    "\n",
    "- Resulting variable has zero mean and unit variance\n",
    "- See [sklearn.preprocessing.StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated Mean: [0.5 0.5]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [3., 3.]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "data = [[0, 0], [0, 0], [1, 1], [1, 1]]\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data)\n",
    "print(\"Estimated Mean: {}\".format(scaler.mean_))\n",
    "scaler.transform([[.5, .5], [2,2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Normalization: Min-Max Scaling   \n",
    "\n",
    "**Min-max scaling**: compute min $\\text{min}_x$ and max $\\text{max}_x$ of $x$\n",
    "\n",
    "$$ x \\leftarrow \\frac{(x - \\text{min}_x) } {\\text{max}_x - \\text{min}_x} $$\n",
    "\n",
    "- Resulting variable is in range [0,1] (or any other range)\n",
    "- See [sklearn.preprocessing.MinMaxScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Categorical Features\n",
    "\n",
    "Categorical features are variables $x \\in \\{ 0,1,2,\\dots, N\\}$ taking one value of a set of cardinality $N$ without an implicit ordering e.g.:\n",
    "- colors (red, green, blue)\n",
    "- user ids\n",
    "- Movie ids\n",
    "\n",
    "Often used feature transformations are \n",
    "\n",
    "- One-hot encoding\n",
    "\n",
    "- More recently for neural networks: low dimensional embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## One-hot encoding\n",
    "\n",
    "Given a set of values [red, green, blue], we transform the data into \n",
    "\n",
    "- red $\\leftarrow [1,0,0]$\n",
    "- green $\\leftarrow [0,1,0]$\n",
    "- blue $\\leftarrow [0,0,1]$\n",
    "\n",
    "Sets of categorical variables can be represented as sum over single value vectors.\n",
    "\n",
    "Examples: bag-of-words vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "X = [['red'], ['green'], ['blue'], ['red']]\n",
    "enc.fit(X)\n",
    "enc.transform([['red'], ['green'], ['blue']]).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## One-hot encoding: Problems\n",
    "\n",
    "- Cardinality needs to be estimated upfront\n",
    "- New items / categories cannot be represented\n",
    "- Similarity information is lost (light-blue and blue as different as black and white)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
