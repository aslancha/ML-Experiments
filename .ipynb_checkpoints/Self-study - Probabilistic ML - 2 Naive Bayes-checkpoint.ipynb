{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CMU 10-601 Machine Learning 2015: HW 3\n",
    "CMU 10-701 Machine Learning 2011: HW 3\n",
    "\n",
    "Problem 1: Implementing Naive Bayes\n",
    "The suggested dataset from the graduate level course 10-601 is changed to the suggested dataset from the PhD level course 10-701 (fetch_20newsgroups) because the dataset from 10-601 is not available. \n",
    "\n",
    "Furthermore, the preprocessing is done by sklearn to focus on the core problem of Naive Bayes.\n",
    "\n",
    "First the Naive Bayes Classifier is implemented from scratch with Beta Priors like described in 10-601.\n",
    "For reference purposes the accuracy of the solution will be compared to the accuracy of sklearn's BernoulliNB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "# categories_multinomial = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']\n",
    "categories_binomial = ['soc.religion.christian', 'comp.graphics']\n",
    "\n",
    "twenty_train = fetch_20newsgroups(subset='train',\n",
    "                                 categories=categories_binomial,\n",
    "                                 shuffle=True,\n",
    "                                 random_state=42)\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
    "\n",
    "twenty_test = fetch_20newsgroups(subset = 'test', \n",
    "                                categories=categories_binomial,\n",
    "                                shuffle=True,\n",
    "                                random_state=42)\n",
    "docs_test = twenty_test.data\n",
    "docs_test_counts = count_vect.transform(docs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1183, 22953)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(183710,)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_counts.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(twenty_train.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing Naive Bayes with BETA Priors from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy self-implemented: 0.9809402795425667\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "         comp.graphics       0.97      0.99      0.98       389\n",
      "soc.religion.christian       0.99      0.97      0.98       398\n",
      "\n",
      "              accuracy                           0.98       787\n",
      "             macro avg       0.98      0.98      0.98       787\n",
      "          weighted avg       0.98      0.98      0.98       787\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# P(Y = 1 | X1, ... , Xn) = P(X1, ... , Xn | Y = 1) * P(Y=1) / sum_y[P(X1, ... , Xn | Y = y) * P(Y=y)]\n",
    "# P(Y = 1 | X1, ... , Xn) = product_i(P(Xi | Y = 1)) * P(Y=1) / sum_y(product_i(P(Xi | Y = y)) * P(Y=y))\n",
    "# P(Xi | Y = 1) = theta_i**n_i * (1-theta_i)**(N - n_i) # -> one vs. all\n",
    "# P(Y = 1) = theta_y1**(n_y1 - 1) * (1-theta_y1)**(n_y0 - 1)\n",
    "# \n",
    "\n",
    "def NB_XGivenY(X_train, y_train):\n",
    "    beta1 = 2\n",
    "    beta0 = 1\n",
    "    theta_MAP = np.zeros((2,X_train.shape[1]))\n",
    "    X_train_given_y1 = X_train[y_train==1]\n",
    "    X_train_given_y0 = X_train[y_train==0]\n",
    "    \n",
    "    X_train_given_y1_ysum = np.sum(X_train_given_y1, axis=0)\n",
    "    X_train_given_y0_ysum = np.sum(X_train_given_y0, axis=0)\n",
    "    X_train_given_y1_total = np.sum(X_train_given_y1_ysum, axis=1)\n",
    "    X_train_given_y0_total = np.sum(X_train_given_y0_ysum, axis=1)\n",
    "    \n",
    "    features_count = X_train_given_y1_ysum.shape[1]\n",
    "    \n",
    "    theta_MAP[0,:] = (X_train_given_y0_ysum + beta1)/(X_train_given_y0_total + features_count*beta0)\n",
    "    theta_MAP[1,:] = (X_train_given_y1_ysum + beta1)/(X_train_given_y1_total + features_count*beta0)  \n",
    "\n",
    "    return theta_MAP\n",
    "\n",
    "def NB_YPrior(y_train):\n",
    "    y1_count = np.sum((y_train==1)*1)\n",
    "    y0_count = np.sum((y_train==0)*1)\n",
    "    return y1_count/(y1_count + y0_count)\n",
    "\n",
    "def NB_Classify(theta_MAP, prior, X_test):\n",
    "    # detect where X is existent\n",
    "    is_feature = (X_test.todense()!=0)*1\n",
    "    # fill with according probability \"1 - theta\" or \"1 - (1 - theta)\"\"\n",
    "    logP_of_X_given_y1 = np.log(np.abs(is_feature - (1-theta_MAP[1]) ) ) \n",
    "    logP_of_X_given_y0 = np.log(np.abs(is_feature - (1-theta_MAP[0]) ) )\n",
    "    \n",
    "    logP_y1_given_X = np.sum(logP_of_X_given_y1, axis=1) + np.log(prior)\n",
    "    logP_y0_given_X = np.sum(logP_of_X_given_y0, axis=1) + np.log(1-prior)\n",
    "    class_probabilities = logP_y1_given_X - logP_y0_given_X\n",
    "\n",
    "    return ( (class_probabilities) > 0 )*1\n",
    "    \n",
    "     \n",
    "\n",
    "theta_MAP = NB_XGivenY(X_train_counts, twenty_train.target)\n",
    "prior = NB_YPrior(twenty_train.target)\n",
    "y_predicted = NB_Classify(theta_MAP, prior, docs_test_counts)\n",
    "y_test = twenty_test.target.reshape(twenty_test.target.shape[0], 1)\n",
    "\n",
    "y_predicted_test = np.concatenate((y_predicted, y_test), axis=1)\n",
    "false_classified_boolean = (y_predicted!=y_test)\n",
    "correct_classified_boolean = (y_predicted==y_test)\n",
    "correct_classified = (correct_classified_boolean)*1\n",
    "correct_classified_sum = np.sum(correct_classified)\n",
    "\n",
    "print(\"Accuracy self-implemented:\", correct_classified_sum/y_predicted.shape[0])\n",
    "print(metrics.classification_report(y_test, \n",
    "                                    y_predicted,\n",
    "                                   target_names=twenty_test.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference purposes, comparing to Sklearn BernoulliNB Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "         comp.graphics       0.86      0.98      0.91       389\n",
      "soc.religion.christian       0.98      0.84      0.90       398\n",
      "\n",
      "              accuracy                           0.91       787\n",
      "             macro avg       0.92      0.91      0.91       787\n",
      "          weighted avg       0.92      0.91      0.91       787\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "clf = BernoulliNB().fit(X_train_counts, twenty_train.target)\n",
    "predicted = clf.predict(docs_test_counts)\n",
    "print(metrics.classification_report(twenty_test.target, \n",
    "                                    predicted,\n",
    "                                   target_names=twenty_test.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing Naive Bayes with DIRICHLET Priors from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
